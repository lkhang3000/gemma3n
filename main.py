"""
Gemma Chatbot - Windows Desktop Application
á»¨ng dá»¥ng chat sá»­ dá»¥ng Gemma AI model
"""

import os
import sys
import traceback
from pathlib import Path

# ThÃªm thÆ° má»¥c root vÃ o Python path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from ui.chat_window import ChatWindow
    import customtkinter as ctk
    from tkinter import messagebox
    import torch
    from transformers import AutoTokenizer
    
except ImportError as e:
    print(f"âŒ Lá»—i import: {e}")
    print("ğŸ“‹ Cáº§n cÃ i Ä‘áº·t cÃ¡c package sau:")
    print("pip install customtkinter transformers torch torchvision torchaudio")
    input("Nháº¥n Enter Ä‘á»ƒ thoÃ¡t...")
    sys.exit(1)

def check_requirements():
    """Kiá»ƒm tra system requirements"""
    print("ğŸ” Äang kiá»ƒm tra system requirements...")
    
    # Kiá»ƒm tra Python version
    if sys.version_info < (3, 8):
        print("âŒ Cáº§n Python 3.8 trá»Ÿ lÃªn")
        return False
        
    # Kiá»ƒm tra GPU (optional)
    if torch.cuda.is_available():
        print(f"âœ… GPU kháº£ dá»¥ng: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n GPU, sáº½ sá»­ dá»¥ng CPU (cháº­m hÆ¡n)")
        
    # Kiá»ƒm tra disk space (cáº§n ~5GB cho model)
    import shutil
    free_space = shutil.disk_usage(".").free / (1024**3)
    if free_space < 5:
        print(f"âš ï¸ Disk space tháº¥p: {free_space:.1f} GB (khuyáº¿n nghá»‹ >= 5GB)")
        
    print("âœ… System requirements OK")
    return True

def setup_environment():
    """Thiáº¿t láº­p mÃ´i trÆ°á»ng"""
    # Táº¡o thÆ° má»¥c cache náº¿u chÆ°a cÃ³
    cache_dir = Path.home() / ".cache" / "gemma_chatbot"
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # Thiáº¿t láº­p Hugging Face cache
    os.environ['HF_HOME'] = str(cache_dir / "huggingface")
    os.environ['TRANSFORMERS_CACHE'] = str(cache_dir / "transformers")
    
    # Thiáº¿t láº­p sá»‘ threads cho CPU
    if not torch.cuda.is_available():
        torch.set_num_threads(4)  # Tá»‘i Æ°u cho CPU
        
    print("ğŸ”§ MÃ´i trÆ°á»ng Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p")

def main():
    """Main function"""
    print("ğŸš€ Khá»Ÿi Ä‘á»™ng Gemma Chatbot...")
    print("=" * 50)
    
    try:
        # Kiá»ƒm tra requirements
        if not check_requirements():
            input("âŒ System requirements khÃ´ng Ä‘á»§. Nháº¥n Enter Ä‘á»ƒ thoÃ¡t...")
            return
            
        # Thiáº¿t láº­p mÃ´i trÆ°á»ng
        setup_environment()
        
        # Khá»Ÿi táº¡o vÃ  cháº¡y á»©ng dá»¥ng
        print("ğŸ¨ Äang khá»Ÿi táº¡o giao diá»‡n...")
        app = ChatWindow()
        
        print("âœ… á»¨ng dá»¥ng Ä‘Ã£ sáºµn sÃ ng!")
        print("ğŸ’¡ Máº¹o: Model sáº½ táº£i trong background, vui lÃ²ng Ä‘á»£i...")
        print("=" * 50)
        
        # Cháº¡y á»©ng dá»¥ng
        app.run()
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Äang thoÃ¡t á»©ng dá»¥ng...")
        
    except Exception as e:
        print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {e}")
        print("\nğŸ“‹ Chi tiáº¿t lá»—i:")
        traceback.print_exc()
        
        # Hiá»ƒn thá»‹ error dialog náº¿u cÃ³ thá»ƒ
        try:
            root = ctk.CTk()
            root.withdraw()  # áº¨n window chÃ­nh
            messagebox.showerror(
                "Lá»—i á»©ng dá»¥ng",
                f"ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n:\n\n{str(e)}\n\nVui lÃ²ng kiá»ƒm tra console Ä‘á»ƒ biáº¿t chi tiáº¿t."
            )
        except:
            pass
            
        input("\nNháº¥n Enter Ä‘á»ƒ thoÃ¡t...")

if __name__ == "__main__":
    main()