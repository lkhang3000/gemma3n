During the process of prompt engineering and fine-tuning the model, I notice some limit of Gemma3n:e2b. 
1)The requirements for CPU and RAM are designed that users withhout high-end GPU can also use the model. However, my laptop has a CPU, which has 2 cores and 4 logical reasons, and RAM, which has 4GB, having trouble to run main.py (you can see the file in chatbot demo). There some part in main.py that I'm unable to test as my laptop has insufficient system. Therefore, I would be grateful if you can take a look at the memory(line 169 to line 300-main.py)
2)If you have a CPU, which has less than 4 cores, RAM with less than 8GB, as an user of chatbot, you won't encounter any issue. However, as a developer, you won't be able to edit the chatbot. My solution for this is put the code on AI and test it( sound stupid as AI can hallucinate but this is the only solution I can think of). During the training, it will be better to only has your coding environment open( Gemma3n can take your whole CPU to run)
3)We still can train the model online(using kagglehub or google colab) but it exposes us to the risk of data leakage(sensitive data can send to API without our consent)
